{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding route to custom libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "\n",
    "dirname = os.path.abspath(os.path.join(os.getcwd(), \"..\", \"scripts/lib\"))\n",
    "sys.path.append(dirname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.compile import compileFolder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"It's not enough to be only exceptional in one realm.\\n\\nWith every single advantage you have,\\n\\nIt's not enough to be good at just ONE thing.\\n\\nYou need to be good at EVERYTHING.\\n\\nRich, Strong, Charismatic, Girl on Lock, Well-Connected, Wise.\\n\\nEVERYTHING.\\n\\nYou have the entire world at your fingertips,\\n\\nSitting in your pocket.\\n\\nI am a BILLIONAIRE writing to you RIGHT NOW.\\n\\nThis is not the past.\\n\\nYou have more knowledge, more resources and less bullshit to deal with than every one of your ancestors.\\n\\nYou cannot just be rich.\\n\\nYou cannot just be strong.\\n\\nOne is not enough anymore.\\n\\nAnd if you do not understand this,\\n\\nYou will simply lose to those who do.\\n\\n \\n\\n- Tate\\n\\n\",\n",
       " 'Inheritance is knowledge and mindset.\\n\\nThat\\'s what a father gives his boys.\\n\\nMoney prevents them from experiencing the harshest lessons.\\n\\nVital lessons.\\n\\n\"I wouldn\\'t leave you a dollar boy, even if I had it!\"\\n\\nMy dad died with zero assets and 12usd in the bank.\\n\\nI\\'m trying to die with 11.\\n\\nHOW can my SON represent ME?\\n\\nIf I was poor and struggling but he wasn\\'t?\\n\\nI can teach but if he\\'s not hungry enough to be taking life-or-death fights for pennies he can\\'t become the man I am. \\n\\nLearn = live \\n\\nMy fortune dies with me.\\n\\nBut with my lessons? \\n\\nHe makes his own.\\n\\nThere is no worse fate for your son but for him to have daddy\\'s money as a safety net. \\n\\nThis generational wealth shit is for soft men who want to replicate soft men. \\n\\nI am not me because I\\'m rich. \\n\\nI\\'m me because I\\'m rich AND everything else. \\n\\nThanks Dad.\\n \\n\\n- Tate\\n\\n',\n",
       " 'There is a small percentage of men in the world who want MORE.\\n\\nMen who REFUSE to live a normal life, who REFUSE to be average or just above average.\\n\\nMen who refuse to be anything less than SPECTACULAR.\\n\\nThere is a man out there who lives the life of YOUR dreams. \\n\\nDoes that fact not leave you restless at night?\\n\\nMost men sleep fine knowing their dreams will remain dreams.\\n\\nBut some men, refuse to have anything less than everything.\\n\\nWe will either live the life of our dreams or die trying.\\n\\nWill you?\\n\\n \\n\\n- Tate',\n",
       " \"Cost is the enemy of the poor man, so the poor try to save money. \\n\\nTime is the enemy of the rich man, so the rich try to save time.\\n\\nWhen I was poor, I still valued Time > Cash.\\n\\nI operated as a rich man long before I became rich.\\n\\nNever waited for a bus, I took a taxi.\\n\\nI was WORKING so hard that I knew my TIME had value.\\n\\nSaving cash to lose time is a subliminal message that your time isn't effective.\\n\\nYou already WASTE time, so you don't need to PAY for more. \\n\\nI buy a 500k car and fly on private jets and amateurs think I'm wasting money.\\n\\nYet they drive slow cars and sit around in airports all day. They're wasting time.\\n\\nI need my time to make more money than I'll spend saving time. \\n\\nA positive feedback loop into infinity. \\n\\nYour time is EXTREMELY valuable when you are doing the right things,\\n\\nYou just need to know the right things to do.\\n\\nDo you understand?\\n\\n \\n\\n- Tate\\n\\n\",\n",
       " \"Most people do not enjoy feeling afraid.\\n\\nThey live their whole lives trying to avoid Fear.\\n\\nThey don't answer his calls,\\n\\nWhen they see him in the distance, they stop walking.\\n\\nIf he knocks at the door, they pretend not to be home.\\n\\nBut Fear is a friend, a very good friend.\\n\\nAnything great has some level of REAL risk.\\n\\nAnd that REAL risk induces REAL fear.\\n\\nThe difference between the great and the average,\\n\\nIs the great do not AVOID fear, they understand him.\\n\\nFear is a signal that you're doing something BIG.\\n\\nFear is the warning to be on your A-game.\\n\\nFear is the sign that lets you know that you CAN NOT FAIL. \\n\\nFear is a friend,\\n\\nHe's there to remind you.\\n\\nThe friend that will show up before every single fight to increase your powers. \\n\\nFear is there before your greatest battles.\\n\\nHe comes with gifts to hand you for the war. \\n\\nYou'll move faster when afraid. Ever jumped in the night?\\n\\nYour hearing is heightened. \\n\\nYour eyesight is sharper. \\n\\nShake his hand, acknowledge his warnings then move forward SUPER CHARGED.\\n\\nDo not avoid fear.\\n\\nFear is at the door of everything great.\\n\\n \\n\\n- Tate\\n\\n\"]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = compileFolder('tate')\n",
    "data[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "76"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compiledText = data\n",
    "if type(data)==list:\n",
    "    compiledText = \" \".join(data)\n",
    "\n",
    "# Feel free to comment next line (it is mainly to add all letters in the alphabet)\n",
    "compiledText += \"\".join([chr(i) for i in range(ord('A'),ord('Z')+1)]) + \"\".join([chr(i) for i in range(ord('a'),ord('z')+1)])\n",
    "\n",
    "temp = list(set(compiledText))\n",
    "temp.append('[S]')\n",
    "temp.append('[E]')\n",
    "vocabulary = sorted(temp)\n",
    "len(vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n !\"\\',-./01234567:=>?ABCDEFGHIJKLMNOPQRSTUVWXYZ[E][S]abcdefghijklmnopqrstuvwxyzâ€¦'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''.join(vocabulary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create encode and decode functtions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a mapping from the characters to integer\n",
    "\n",
    "stoi = { ch:i for i,ch in enumerate(vocabulary)}\n",
    "itos = { i:ch for i,ch in enumerate(vocabulary)}\n",
    "\n",
    "encode = lambda s: [stoi[c] for c in s]\n",
    "decode = lambda l: ''.join([itos[i] for i in l])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[28, 53, 60, 60, 63, 1, 61, 73, 1, 54, 66, 57, 53, 62, 52, 2]\n",
      "Hello my friend!\n"
     ]
    }
   ],
   "source": [
    "encoded = encode('Hello my friend!')\n",
    "print(encoded)\n",
    "decoded = decode(encoded)\n",
    "print(decoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation of the code in the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.tokenizer import CharTokenizer\n",
    "\n",
    "tokenizer = CharTokenizer(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([46, 28, 52, 59, 59, 62,  1, 70, 62, 65])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = tokenizer.encode(\"Hello world! How is everyone doing?\", isMiddle=False)\n",
    "tokens[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[E]', 'H', 'e', 'l', 'l', 'o', ' ', 'w', 'o', 'r']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(tokens)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello world! How is everyone doing?'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decodeText(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenize all the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "tokenizedData = []\n",
    "for chunk in data:\n",
    "    tokenizedData.append(tokenizer.encode(chunk))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([29, 67,  4, 66,  1, 61, 62, 67,  1, 52, 61, 62, 68, 54, 55,  1, 67, 62,\n",
       "         1, 49, 52,  1, 62, 61, 59, 72,  1, 52, 71, 50, 52, 63, 67, 56, 62, 61,\n",
       "        48, 59,  1, 56, 61,  1, 62, 61, 52,  1, 65, 52, 48, 59, 60,  7,  0,  0,\n",
       "        42, 56, 67, 55,  1, 52, 69, 52, 65, 72,  1, 66, 56, 61, 54, 59, 52,  1,\n",
       "        48, 51, 69, 48, 61, 67, 48, 54, 52,  1, 72, 62, 68,  1, 55, 48, 69, 52,\n",
       "         5,  0,  0, 29, 67,  4, 66,  1, 61, 62, 67,  1, 52, 61, 62, 68, 54, 55,\n",
       "         1, 67, 62,  1, 49, 52,  1, 54, 62, 62, 51,  1, 48, 67,  1, 57, 68, 66,\n",
       "        67,  1, 34, 33, 25,  1, 67, 55, 56, 61, 54,  7,  0,  0, 44, 62, 68,  1,\n",
       "        61, 52, 52, 51,  1, 67, 62,  1, 49, 52,  1, 54, 62, 62, 51,  1, 48, 67,\n",
       "         1, 25, 41, 25, 37, 44, 39, 28, 29, 33, 27,  7,  0,  0, 37, 56, 50, 55,\n",
       "         5,  1, 38, 67, 65, 62, 61, 54,  5,  1, 23, 55, 48, 65, 56, 66, 60, 48,\n",
       "        67, 56])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizedData[0][:200]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion:\n",
    "This `HTokenizer` class is a character tokenizer, and we will use it for tokenizing the data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
